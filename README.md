# Narah HC Processor

Sistema profesional de procesamiento automatizado de historias cl√≠nicas ocupacionales para **Narah Metrics 2.0**.

Transforma PDFs de historias cl√≠nicas (nativos o escaneados) en datos estructurados JSON mediante Azure Document Intelligence y Claude API (Anthropic).

---

## üéØ Caracter√≠sticas Principales

- ‚úÖ **Extracci√≥n de PDFs**: Soporte para documentos nativos y escaneados (OCR) con Azure Document Intelligence
- ‚úÖ **Procesamiento Inteligente**: Estructuraci√≥n de datos m√©dicos con Claude Sonnet 4
- ‚úÖ **Validaci√≥n Robusta**: Validaci√≥n autom√°tica de CIE-10, fechas, y valores cl√≠nicos
- ‚úÖ **Alertas M√©dicas**: Detecci√≥n autom√°tica de inconsistencias y valores cr√≠ticos
- ‚úÖ **Export Flexible**: JSON estructurado y Excel para an√°lisis
- ‚úÖ **CLI Intuitivo**: Interfaz de l√≠nea de comandos con Rich (colores y progress bars)
- ‚úÖ **Batch Processing**: Procesamiento paralelo de m√∫ltiples historias cl√≠nicas
- ‚úÖ **An√°lisis de Calidad**: Script estad√≠stico para evaluar calidad del procesamiento batch
- ‚úÖ **Validaci√≥n Manual**: Herramienta interactiva para crear ground truth y validar campos

---

## üìã Requisitos Previos

### 1. Python 3.10+

```bash
python --version  # Debe ser >= 3.10
```

### 2. Credenciales Azure Document Intelligence

Necesitas crear un recurso de **Azure Document Intelligence** (antes Form Recognizer):

1. Ve a [Azure Portal](https://portal.azure.com)
2. Crea un recurso de "Document Intelligence" o "Form Recognizer"
3. Copia el **Endpoint** y una **API Key** desde "Keys and Endpoint"

### 3. API Key de Anthropic Claude

1. Ve a [Anthropic Console](https://console.anthropic.com/settings/keys)
2. Genera una API Key
3. Aseg√∫rate de tener cr√©ditos disponibles

---

## üöÄ Instalaci√≥n

### Paso 1: Clonar el repositorio

```bash
git clone <repository-url>
cd narah-hc-processor
```

### Paso 2: Crear entorno virtual

```bash
python -m venv venv

# Activar en Linux/Mac
source venv/bin/activate

# Activar en Windows
venv\Scripts\activate
```

### Paso 3: Instalar dependencias

```bash
pip install -r requirements.txt
```

### Paso 4: Configurar variables de entorno

```bash
# Copiar el template
cp .env.example .env

# Editar .env con tus credenciales
nano .env  # o usa tu editor favorito
```

**Configuraci√≥n m√≠nima requerida en `.env`:**

```env
# Azure Document Intelligence
AZURE_DOC_INTELLIGENCE_ENDPOINT=https://your-resource.cognitiveservices.azure.com/
AZURE_DOC_INTELLIGENCE_KEY=your_32_character_key_here

# Anthropic Claude API
ANTHROPIC_API_KEY=sk-ant-api03-your-key-here

# Opcional: Configuraci√≥n
LOG_LEVEL=INFO
CLAUDE_MODEL=claude-sonnet-4-20250514
```

### Paso 5: Verificar instalaci√≥n

```bash
python -m src.cli --version
```

Deber√≠as ver: `cli, version 1.0.0`

---

## üìñ Gu√≠a de Uso

### Comandos Disponibles

```bash
python -m src.cli --help
```

#### 1. Procesar una HC individual

```bash
python -m src.cli process data/raw/HC_001.pdf
```

**Opciones:**

- `--output`, `-o`: Directorio de salida (default: `data/processed/`)
- `--show-result`, `-s`: Mostrar resumen del resultado en consola
- `--save-extraction`: Guardar texto extra√≠do por Azure (√∫til para debugging)

**Ejemplo completo:**

```bash
python -m src.cli process data/raw/HC_123.pdf \
  --output ./output \
  --show-result \
  --save-extraction
```

**Output:**

- `output/HC_123.json`: Historia cl√≠nica estructurada
- `output/HC_123_extraction.txt`: Texto extra√≠do (si se usa `--save-extraction`)

---

#### 2. Procesar m√∫ltiples HCs en batch

```bash
python -m src.cli batch data/raw/
```

**Opciones:**

- `--output`, `-o`: Directorio de salida
- `--workers`, `-w`: N√∫mero de workers paralelos (default: 5)
- `--pattern`, `-p`: Patr√≥n de archivos (default: `*.pdf`)

**Ejemplo:**

```bash
python -m src.cli batch data/raw/ \
  --output data/processed/ \
  --workers 10 \
  --pattern "HC_*.pdf"
```

**Nota:** El procesamiento es secuencial (no paralelo real) debido a l√≠mites de rate de APIs.

---

#### 3. Ver resumen de HC procesada

```bash
python -m src.cli show data/processed/HC_001.json
```

**Muestra:**

- Datos del empleado
- Tipo y fecha del EMO
- Aptitud laboral y restricciones
- Diagn√≥sticos (CIE-10)
- Ex√°menes realizados
- Programas SVE recomendados
- Alertas de validaci√≥n

---

#### 4. Exportar a formato Narah Metrics

```bash
python -m src.cli export-narah data/processed/ --output narah_import.xlsx
```

**Genera un Excel con:**

- Hoja "Resumen": Datos generales de todos los empleados
- Hoja "Diagn√≥sticos": Todos los diagn√≥sticos con CIE-10
- Hoja "Ex√°menes": Resultados de ex√°menes paracl√≠nicos
- Hoja "Recomendaciones": Recomendaciones m√©dicas y ocupacionales
- Hoja "Alertas": Alertas de validaci√≥n detectadas

---

#### 5. Analizar calidad del batch procesado

**Nuevo:** Script de an√°lisis estad√≠stico para evaluar la calidad del procesamiento batch.

```bash
# An√°lisis b√°sico (muestra en terminal)
python analyze_batch.py

# An√°lisis con export a Excel
python analyze_batch.py --export estadisticas.xlsx

# Analizar directorio personalizado
python analyze_batch.py --dir ./custom_dir --export report.xlsx
```

**El an√°lisis incluye:**

- **M√©tricas generales**: Total de HCs, confianza promedio/m√≠n/m√°x
- **Alertas de validaci√≥n**:
  - Total por severidad (alta/media/baja)
  - Top 5 tipos de alertas m√°s comunes
  - HCs con/sin alertas
- **Campos con baja confianza**: Top 10 campos m√°s afectados
- **Tipos de EMO**: Distribuci√≥n (preingreso, peri√≥dico, etc.)
- **Diagn√≥sticos CIE-10**:
  - Top 10 m√°s frecuentes
  - Total y promedio por HC
  - Relacionados con trabajo
- **Aptitud laboral**: Distribuci√≥n (apto, con restricciones, etc.)
- **Programas SVE**: Top 5 programas m√°s asignados
- **Ex√°menes paracl√≠nicos**: Distribuci√≥n por tipo

**Output en terminal:**

El script usa Rich para mostrar tablas formateadas con colores en la terminal.

**Export a Excel:**

Genera archivo con 7 hojas:
1. Resumen
2. Confianza
3. Alertas
4. Diagn√≥sticos
5. Aptitud
6. Programas SVE
7. Ex√°menes

**Ejemplo de uso t√≠pico:**

```bash
# 1. Procesar batch de HCs
python -m src.cli batch data/raw/ --workers 5

# 2. Analizar calidad del procesamiento
python analyze_batch.py --export analisis_calidad.xlsx

# 3. Revisar estad√≠sticas y ajustar si es necesario
```

---

#### 6. Validar y crear ground truth

**Nuevo:** Herramienta interactiva para validar manualmente historias cl√≠nicas y crear ground truth de alta calidad.

```bash
# Validar una HC procesada
python validate_ground_truth.py data/raw/HC_001.pdf data/processed/HC_001.json

# Con directorio de salida personalizado
python validate_ground_truth.py HC_001.pdf HC_001.json --output data/labeled/
```

**Funcionalidad:**

El validador muestra **cada campo del JSON** junto con el **contexto del PDF original**, permitiendo:

- **[C]orrecto**: Marcar campo como v√°lido
- **[E]ditar**: Corregir el valor manualmente
- **[S]altar**: Revisar m√°s tarde
- **[Q]uit**: Guardar progreso y salir

**Interfaz interactiva:**

- ‚úÖ UI con Rich (colores, tablas, paneles)
- ‚úÖ Navegaci√≥n simple con teclas
- ‚úÖ Progress tracking (campo X de Y)
- ‚úÖ Resalta campos con baja confianza en amarillo
- ‚úÖ Campos con alertas en rojo
- ‚úÖ Muestra contexto del PDF relevante

**Campos validados (orden de prioridad):**

1. Datos del empleado (nombre, documento, cargo, empresa)
2. Tipo y fecha de EMO
3. Aptitud laboral y restricciones
4. Diagn√≥sticos (CIE-10, descripci√≥n) - Top 3
5. Ex√°menes (resultados, hallazgos) - Top 3
6. Recomendaciones - Top 2

**Output generado:**

```
data/labeled/
‚îú‚îÄ‚îÄ HC_001.json                      # JSON validado (ground truth)
‚îî‚îÄ‚îÄ HC_001_validation_report.txt    # Reporte detallado
```

**Reporte incluye:**

- Estad√≠sticas de validaci√≥n
- Precisi√≥n del sistema (% campos correctos)
- Lista de todas las correcciones realizadas
- Campos con baja confianza original
- Alertas de validaci√≥n original

**Ejemplo de uso:**

```bash
# 1. Procesar HC
python -m src.cli process data/raw/HC_001.pdf

# 2. Validar manualmente
python validate_ground_truth.py data/raw/HC_001.pdf data/processed/HC_001.json

# Durante la validaci√≥n:
# - Revisa cada campo uno por uno
# - Marca correctos o edita los incorrectos
# - El progreso se guarda autom√°ticamente

# 3. Usar ground truth para evaluaci√≥n
# Ahora tienes data/labeled/HC_001.json validado manualmente
```

**Casos de uso:**

- **Crear dataset de evaluaci√≥n**: Validar 10-20 HCs para medir precisi√≥n real
- **Identificar errores sistem√°ticos**: Ver qu√© campos se corrigen m√°s frecuentemente
- **Mejorar prompts**: Usar correcciones para ajustar el prompt de Claude
- **Auditor√≠a de calidad**: Revisar HCs cr√≠ticas manualmente

---

## üìä Estructura de Datos (Schema)

El sistema genera JSONs con la siguiente estructura:

```json
{
  "id_procesamiento": "uuid-generado",
  "fecha_procesamiento": "2024-03-15T10:30:00",
  "archivo_origen": "HC_001.pdf",

  "datos_empleado": {
    "nombre_completo": "JUAN P√âREZ",
    "documento": "12345678",
    "tipo_documento": "CC",
    "cargo": "Operario de producci√≥n",
    "empresa": "EMPRESA XYZ S.A.S"
  },

  "tipo_emo": "periodico",
  "fecha_emo": "2024-03-10",

  "diagnosticos": [
    {
      "codigo_cie10": "M54.5",
      "descripcion": "Dolor lumbar bajo",
      "tipo": "principal",
      "relacionado_trabajo": true,
      "confianza": 0.95
    }
  ],

  "examenes": [
    {
      "tipo": "laboratorio",
      "nombre": "Hemograma completo",
      "resultado": "Normal",
      "interpretacion": "normal"
    }
  ],

  "aptitud_laboral": "apto_con_restricciones",
  "restricciones_especificas": "No levantar cargas mayores a 15kg",

  "programas_sve": ["dme"],

  "confianza_extraccion": 0.92,

  "alertas_validacion": [
    {
      "tipo": "inconsistencia_diagnostica",
      "severidad": "media",
      "campo_afectado": "diagnosticos",
      "descripcion": "Diagn√≥stico sin soporte en ex√°menes",
      "accion_sugerida": "Verificar con m√©dico evaluador"
    }
  ]
}
```

**Schema completo:** Ver `config/schemas/output_schema.json`

**Modelo Pydantic:** Ver `src/config/schemas.py`

---

## üîç Validaciones Implementadas

El sistema valida autom√°ticamente:

### 1. C√≥digos CIE-10

- ‚úÖ Formato: `A00.0` (Letra + 2 d√≠gitos + punto + 1 d√≠gito)
- ‚úÖ Rangos v√°lidos por cap√≠tulo (A-Z)
- ‚úÖ Alerta si formato es incorrecto

### 2. Fechas

- ‚úÖ Formato ISO: `YYYY-MM-DD`
- ‚úÖ Rango razonable (√∫ltimos 5 a√±os para EMOs)
- ‚úÖ No fechas futuras

### 3. Valores Cl√≠nicos Cr√≠ticos

- ‚ö†Ô∏è Presi√≥n arterial ‚â• 180/110 (crisis hipertensiva)
- ‚ö†Ô∏è Glicemia ‚â• 200 mg/dL
- ‚ö†Ô∏è IMC < 16 o > 40
- ‚ö†Ô∏è Saturaci√≥n de ox√≠geno < 90%

### 4. Consistencia de Datos

- ‚ùå Diagn√≥stico sin c√≥digo CIE-10
- ‚ùå Aptitud laboral no definida
- ‚ùå Restricciones sin diagn√≥sticos que las justifiquen
- ‚ùå Diagn√≥stico mencionado pero sin soporte en ex√°menes

---

## üõ†Ô∏è Troubleshooting

### Error: "Azure Document Intelligence credentials no configuradas"

**Soluci√≥n:**

1. Verifica que el archivo `.env` existe
2. Verifica que `AZURE_DOC_INTELLIGENCE_ENDPOINT` y `AZURE_DOC_INTELLIGENCE_KEY` est√°n configurados
3. El endpoint debe empezar con `https://`

### Error: "Anthropic API key inv√°lida"

**Soluci√≥n:**

1. Verifica que `ANTHROPIC_API_KEY` est√° en `.env`
2. La key debe empezar con `sk-ant-`
3. Verifica que tienes cr√©ditos en tu cuenta de Anthropic

### Error: "No se pudo parsear respuesta de Claude"

**Posibles causas:**

1. El texto extra√≠do por Azure est√° muy corrupto
2. El PDF tiene formato muy at√≠pico
3. Claude no pudo generar JSON v√°lido

**Soluci√≥n:**

1. Usa `--save-extraction` para ver el texto extra√≠do
2. Verifica la calidad del PDF original
3. Revisa los logs en `logs/`

### PDFs escaneados no se procesan bien

**Soluci√≥n:**

1. Azure Document Intelligence requiere PDFs con buena calidad de escaneo
2. Resoluci√≥n m√≠nima recomendada: 300 DPI
3. Aseg√∫rate de que el texto sea legible

### Rate limit de APIs

**Claude API:**

- Free tier: ~5 requests/minuto
- Paid tier: Var√≠a seg√∫n plan

**Azure:**

- Free tier: 500 p√°ginas/mes
- Paid tier: Ilimitado con cuota

**Soluci√≥n:** Usa `--workers 1` para procesamiento m√°s lento pero seguro.

---

## üìÅ Estructura del Proyecto

```
narah-hc-processor/
‚îú‚îÄ‚îÄ README.md                    # Este archivo
‚îú‚îÄ‚îÄ requirements.txt             # Dependencias Python
‚îú‚îÄ‚îÄ pyproject.toml              # Configuraci√≥n del proyecto
‚îú‚îÄ‚îÄ .env.example                # Template de variables de entorno
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ analyze_batch.py            # Script de an√°lisis estad√≠stico de batch
‚îú‚îÄ‚îÄ validate_ground_truth.py    # Herramienta de validaci√≥n manual
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ cli.py                   # CLI principal
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ settings.py          # Configuraci√≥n global
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py           # Schemas Pydantic
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ extractors/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py              # Interface base
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ azure_extractor.py   # Extractor con Azure
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ processors/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prompts.py           # Prompts para Claude
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validators.py        # Validadores
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ claude_processor.py  # Procesador principal
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ exporters/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ json_exporter.py     # Export a JSON
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ excel_exporter.py    # Export a Excel
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ logger.py            # Sistema de logging
‚îÇ       ‚îî‚îÄ‚îÄ helpers.py           # Funciones auxiliares
‚îÇ
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ prompts/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ extraction_prompt.txt  # Prompt maestro
‚îÇ   ‚îî‚îÄ‚îÄ schemas/
‚îÇ       ‚îî‚îÄ‚îÄ output_schema.json     # JSON Schema
‚îÇ
‚îú‚îÄ‚îÄ data/                        # Gitignored (contiene PHI)
‚îÇ   ‚îú‚îÄ‚îÄ raw/                     # PDFs originales
‚îÇ   ‚îú‚îÄ‚îÄ processed/               # JSONs procesados
‚îÇ   ‚îî‚îÄ‚îÄ labeled/                 # Ground truth (evaluaci√≥n)
‚îÇ
‚îî‚îÄ‚îÄ tests/
    ‚îú‚îÄ‚îÄ test_validators.py
    ‚îî‚îÄ‚îÄ test_helpers.py
```

---

## üß™ Tests

Ejecutar tests:

```bash
# Todos los tests
pytest

# Con cobertura
pytest --cov=src

# Verbose
pytest -v

# Un archivo espec√≠fico
pytest tests/test_validators.py
```

---

## üîê Seguridad y Privacidad

**‚ö†Ô∏è IMPORTANTE: Este sistema procesa informaci√≥n m√©dica protegida (PHI)**

### Recomendaciones:

1. **Nunca** commitear archivos `.env` con credenciales
2. **Nunca** commitear PDFs o JSONs con datos de pacientes
3. Los directorios `data/raw/`, `data/processed/`, y `data/labeled/` est√°n en `.gitignore`
4. Aseg√∫rate de cumplir con regulaciones locales (HIPAA, GDPR, Ley 1581 Colombia)
5. Usa Azure y Anthropic con sus configuraciones de privacidad habilitadas

### Cumplimiento Colombia:

- ‚úÖ Ley 1581 de 2012 (Protecci√≥n de Datos Personales)
- ‚úÖ Resoluci√≥n 2346 de 2007 (EMO en Colombia)
- ‚úÖ No almacena datos sensibles sin consentimiento

---

## üìà Roadmap

Futuras mejoras planeadas:

- [ ] Soporte para m√∫ltiples idiomas
- [ ] Detecci√≥n autom√°tica de tipo de EMO
- [ ] Integraci√≥n directa con API de Narah Metrics
- [ ] Dashboard web para visualizaci√≥n
- [ ] Exportaci√≥n a FHIR (Fast Healthcare Interoperability Resources)
- [ ] Reconocimiento de firmas m√©dicas
- [ ] Validaci√≥n contra cat√°logo oficial CIE-10

---

## ü§ù Contribuciones

Para contribuir al proyecto:

1. Fork el repositorio
2. Crea una rama: `git checkout -b feature/nueva-funcionalidad`
3. Commit tus cambios: `git commit -m 'Agregar nueva funcionalidad'`
4. Push: `git push origin feature/nueva-funcionalidad`
5. Abre un Pull Request

---

## üìÑ Licencia

Propietario - Narah Metrics ¬© 2024

---

## üìû Soporte

Para soporte t√©cnico:

- Email: dev@narahmetrics.com
- Documentaci√≥n completa en el c√≥digo fuente

---

## ‚ú® Cr√©ditos

Desarrollado para **Narah Metrics 2.0**

**Stack Tecnol√≥gico:**

- [Azure Document Intelligence](https://azure.microsoft.com/en-us/products/ai-services/ai-document-intelligence)
- [Anthropic Claude API](https://www.anthropic.com/api)
- [Pydantic](https://docs.pydantic.dev/)
- [Click](https://click.palletsprojects.com/)
- [Rich](https://rich.readthedocs.io/)

---

**¬°Listo para procesar historias cl√≠nicas! üöÄ**
